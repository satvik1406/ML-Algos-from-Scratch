{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwAG4jKhOx2B"
      },
      "source": [
        "## 2 Layered Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhrtz8pMv05"
      },
      "source": [
        "# Backprop on the Seeds Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from random import random\n",
        "from random import gauss\n",
        "from random import uniform\n",
        "from random import shuffle\n",
        "from csv import reader\n",
        "from math import exp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from statistics import stdev\n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue #[[],[]]\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (float(row[i]) - float(minmax[i][0])) / (float(minmax[i][1]) - float(minmax[i][0]))\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "def evaluate_algorithm(dataset, algorithm, *args):\n",
        "  shuffle(dataset)\n",
        "  train_set = dataset[:int(0.7*len(dataset))]\n",
        "  test_set = dataset[int(0.7*len(dataset))+1:]\n",
        "  scores = list()\n",
        "  predicted = algorithm(train_set, test_set, *args)\n",
        "  print(len(predicted))\n",
        "  actual = [row[-1] for row in test_set]\n",
        "  print(len(actual))\n",
        "  accuracy = accuracy_metric(actual, predicted)\n",
        "  scores.append(accuracy)\n",
        "  return scores\n",
        " \n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        " \n",
        "# Transfer neuron activation\n",
        "def transfer_sigmoid(activation):\n",
        "    return 1.0 / (1.0 + exp(-activation))#sigmoid\n",
        "\n",
        "\n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'],inputs)\n",
        "\t\t\tneuron['output'] = transfer_sigmoid(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        " \n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative_sigmoid(output):\n",
        "\treturn output * (1.0 - output)\n",
        "\n",
        "def transfer_derivative_relu(output):\n",
        "\tif output<=0:\n",
        "\t\treturn 0\n",
        "\telse:\n",
        "\t\treturn 1\n",
        " \n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative_sigmoid(neuron['output'])\n",
        " \n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "  \n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "  errors=list()\n",
        "  sum_error=None\n",
        "  acc_values=list()\n",
        "  iter=list()\n",
        "  for epoch in range(n_epoch):\n",
        "    sum_error=0\n",
        "    act=list()\n",
        "    for r in train:\n",
        "      act.append(r[-1])\n",
        "    for row in train:\n",
        "      outputs=forward_propagate(network,row)\n",
        "      expected=[0 for i in range(n_outputs)]\n",
        "      expected[row[-1]] = 1\n",
        "      sum_error+=np.linalg.norm(np.array([x1 - x2 for (x1, x2) in zip(outputs, expected)]))\n",
        "      backward_propagate_error(network, expected)\n",
        "      update_weights(network, row, l_rate)\n",
        "    errors.append(sum_error)\n",
        "    if epoch%50==0:\n",
        "      pred=list()\n",
        "      for row in train:\n",
        "        p=predict(network,row)\n",
        "        # print(len(act))\n",
        "        # print(len(p))\n",
        "        pred.append(p)\n",
        "      acc_values.append(accuracy_metric(act,pred))\n",
        "      iter.append(epoch)\n",
        "  x = [i for i in range(1,len(errors)+1)]\n",
        "  y = errors\n",
        "  print('____TRAIN DATA____')\n",
        "  print('Average Cost:',float(sum(errors))/float(len(errors)))\n",
        "  print('Average Cost:',float(sum(acc_values))/float(len(acc_values)))\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Error(Mean Squared)')\n",
        "  plt.title('Epochs vs Error')\n",
        "  plt.show()\n",
        "  # print(acc_values)\n",
        "  # print(iter)\n",
        "  plt.plot(iter,acc_values)\n",
        "  plt.xlabel('Epoches')\n",
        "  plt.ylabel('Accuracies')\n",
        "  plt.title('Epochs vs Accuracies')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "  # print(n_outputs)\n",
        "  network = list()\n",
        "  hidden_layer_1 = [{'weights':[uniform(0,1) for i in range(n_inputs + 1)]} for i in range(n_hidden[0])]\n",
        "  network.append(hidden_layer_1)\n",
        "  hidden_layer_2 = [{'weights':[uniform(0,1) for i in range(n_hidden[0] + 1)]} for i in range(n_hidden[1])]\n",
        "  network.append(hidden_layer_2)\n",
        "  output_layer = [{'weights':[uniform(0,1) for i in range(n_hidden[1] + 1)]} for i in range(n_outputs)]\n",
        "  network.append(output_layer)\n",
        "  return network\n",
        " \n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        " \n",
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "\tn_inputs = len(train[0]) - 1\n",
        "\tn_outputs = len(set([row[-1] for row in train]))\n",
        "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(network, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn(predictions)\n",
        " \n",
        "# Test Backprop on Seeds dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'dataset_NN.csv'\n",
        "dataset = load_csv(filename)\n",
        "# print(dataset)\n",
        "dataset.pop(0)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# # convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# normalize input variables\n",
        "\n",
        "minmax = dataset_minmax(dataset)\n",
        "# print(minmax)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "l_rate = 0.01\n",
        "n_epoch = 5000 #500\n",
        "n_hidden = [5,5]#list of number of neurons in each hidden layer\n",
        "accuracies = evaluate_algorithm(dataset, back_propagation,l_rate, n_epoch, n_hidden)\n",
        "# print('Accuracies: %s' % accuracies)\n",
        "print('____TEST DATA____')\n",
        "print('Average Accuracy: %.3f%%' % (sum(accuracies)/float(len(accuracies))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P55X4PAkO8QZ"
      },
      "source": [
        "## 1 Layered Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbWZbjYWMv1I"
      },
      "source": [
        "# Backprop on the Seeds Dataset\n",
        "from random import seed\n",
        "from random import randrange\n",
        "from random import random\n",
        "from csv import reader\n",
        "from math import exp\n",
        " \n",
        "# Load a CSV file\n",
        "def load_csv(filename):\n",
        "\tdataset = list()\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\tcsv_reader = reader(file)\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif not row:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdataset.append(row)\n",
        "\treturn dataset\n",
        " \n",
        "# Convert string column to float\n",
        "def str_column_to_float(dataset, column):\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = float(row[column].strip())\n",
        " \n",
        "# Convert string column to integer\n",
        "def str_column_to_int(dataset, column):\n",
        "\tclass_values = [row[column] for row in dataset]\n",
        "\tunique = set(class_values)\n",
        "\tlookup = dict()\n",
        "\tfor i, value in enumerate(unique):\n",
        "\t\tlookup[value] = i\n",
        "\tfor row in dataset:\n",
        "\t\trow[column] = lookup[row[column]]\n",
        "\treturn lookup\n",
        " \n",
        "# Find the min and max values for each column\n",
        "def dataset_minmax(dataset):\n",
        "\tminmax = list()\n",
        "\tstats = [[min(column), max(column)] for column in zip(*dataset)]\n",
        "\treturn stats\n",
        " \n",
        "# Rescale dataset columns to the range 0-1\n",
        "def normalize_dataset(dataset, minmax):\n",
        "\tfor row in dataset:\n",
        "\t\tfor i in range(len(row)-1):\n",
        "\t\t\trow[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
        " \n",
        "# Calculate accuracy percentage\n",
        "def accuracy_metric(actual, predicted):\n",
        "\tcorrect = 0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tif actual[i] == predicted[i]:\n",
        "\t\t\tcorrect += 1\n",
        "\treturn correct / float(len(actual)) * 100.0\n",
        "\n",
        "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
        "  shuffle(dataset)\n",
        "  train_set = dataset[:int(0.7*len(dataset))]\n",
        "  test_set = dataset[int(0.7*len(dataset))+1:]\n",
        "  # print(train_set)\n",
        "  scores = list()\n",
        "  predicted = algorithm(train_set, test_set, *args)\n",
        "  # print(len(predicted))\n",
        "  actual = [row[-1] for row in test_set]\n",
        "  # print(len(actual))\n",
        "  accuracy = accuracy_metric(actual, predicted)\n",
        "  scores.append(accuracy)\n",
        "  return scores\n",
        "# Calculate neuron activation for an input\n",
        "def activate(weights, inputs):\n",
        "\tactivation = weights[-1]\n",
        "\tfor i in range(len(weights)-1):\n",
        "\t\tactivation += weights[i] * inputs[i]\n",
        "\treturn activation\n",
        " \n",
        "# Transfer neuron activation\n",
        "def transfer(activation):\n",
        "\treturn 1.0 / (1.0 + exp(-activation))\n",
        " \n",
        "# Forward propagate input to a network output\n",
        "def forward_propagate(network, row):\n",
        "\tinputs = row\n",
        "\tfor layer in network:\n",
        "\t\tnew_inputs = []\n",
        "\t\tfor neuron in layer:\n",
        "\t\t\tactivation = activate(neuron['weights'], inputs)\n",
        "\t\t\tneuron['output'] = transfer(activation)\n",
        "\t\t\tnew_inputs.append(neuron['output'])\n",
        "\t\tinputs = new_inputs\n",
        "\treturn inputs\n",
        " \n",
        "# Calculate the derivative of an neuron output\n",
        "def transfer_derivative(output):\n",
        "\treturn output * (1.0 - output)\n",
        " \n",
        "# Backpropagate error and store in neurons\n",
        "def backward_propagate_error(network, expected):\n",
        "\tfor i in reversed(range(len(network))):\n",
        "\t\tlayer = network[i]\n",
        "\t\terrors = list()\n",
        "\t\tif i != len(network)-1:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\terror = 0.0\n",
        "\t\t\t\tfor neuron in network[i + 1]:\n",
        "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
        "\t\t\t\terrors.append(error)\n",
        "\t\telse:\n",
        "\t\t\tfor j in range(len(layer)):\n",
        "\t\t\t\tneuron = layer[j]\n",
        "\t\t\t\terrors.append(expected[j] - neuron['output'])\n",
        "\t\tfor j in range(len(layer)):\n",
        "\t\t\tneuron = layer[j]\n",
        "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
        " \n",
        "# Update network weights with error\n",
        "def update_weights(network, row, l_rate):\n",
        "\tfor i in range(len(network)):\n",
        "\t\tinputs = row[:-1]\n",
        "\t\tif i != 0:\n",
        "\t\t\tinputs = [neuron['output'] for neuron in network[i - 1]]\n",
        "\t\tfor neuron in network[i]:\n",
        "\t\t\tfor j in range(len(inputs)):\n",
        "\t\t\t\tneuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
        "\t\t\tneuron['weights'][-1] += l_rate * neuron['delta']\n",
        "\n",
        "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
        "  errors=list()\n",
        "  sum_error=0\n",
        "  acc_values=list()\n",
        "  iter=list()\n",
        "  for epoch in range(n_epoch):\n",
        "    act=list()\n",
        "    for r in train:\n",
        "      act.append(r[-1])\n",
        "    for row in train:\n",
        "      outputs=forward_propagate(network, row)\n",
        "      expected=[0 for i in range(n_outputs)]\n",
        "      expected[row[-1]] = 1\n",
        "      sum_error=np.linalg.norm(np.array([x1 - x2 for (x1, x2) in zip(outputs, expected)]))\n",
        "      backward_propagate_error(network, expected)\n",
        "      update_weights(network, row, l_rate)\n",
        "    errors.append(sum_error)\n",
        "    if epoch%50==0:\n",
        "      pred=list()\n",
        "      for row in train:\n",
        "        p=predict(network,row)\n",
        "        # print(len(act))\n",
        "        # print(len(p))\n",
        "        pred.append(p)\n",
        "      acc_values.append(accuracy_metric(act,pred))\n",
        "      iter.append(epoch)\n",
        "  x = [i for i in range(1,len(errors)+1)]\n",
        "  y = errors\n",
        "  print('____TRAIN DATA____')\n",
        "  print('Average Cost:',float(sum(errors))/float(len(errors)))\n",
        "  print('Average Accuracy:',float(sum(acc_values))/float(len(acc_values)))\n",
        "  plt.plot(x, y)\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Error(Mean Squared)')\n",
        "  plt.title('Epochs vs Error')\n",
        "  plt.show()\n",
        "  # print(acc_values)\n",
        "  # print(iter)\n",
        "  plt.plot(iter,acc_values)\n",
        "  plt.xlabel('Epoches')\n",
        "  plt.ylabel('Accuracies')\n",
        "  plt.title('Epochs vs Accuracies')\n",
        "  plt.show()\n",
        "\n",
        "# Initialize a network\n",
        "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
        "\tnetwork = list()\n",
        "\thidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
        "\tnetwork.append(hidden_layer)\n",
        "\toutput_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
        "\tnetwork.append(output_layer)\n",
        "\treturn network\n",
        " \n",
        "# Make a prediction with a network\n",
        "def predict(network, row):\n",
        "\toutputs = forward_propagate(network, row)\n",
        "\treturn outputs.index(max(outputs))\n",
        " \n",
        "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
        "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
        "\tn_inputs = len(train[0]) - 1\n",
        "\tn_outputs = len(set([row[-1] for row in train]))\n",
        "\tnetwork = initialize_network(n_inputs, n_hidden, n_outputs)\n",
        "\ttrain_network(network, train, l_rate, n_epoch, n_outputs)\n",
        "\tpredictions = list()\n",
        "\tfor row in test:\n",
        "\t\tprediction = predict(network, row)\n",
        "\t\tpredictions.append(prediction)\n",
        "\treturn predictions\n",
        " \n",
        "# Test Backprop on Seeds dataset\n",
        "seed(1)\n",
        "# load and prepare data\n",
        "filename = 'dataset_NN.csv'\n",
        "dataset = load_csv(filename)\n",
        "dataset.pop(0)\n",
        "for i in range(len(dataset[0])-1):\n",
        "\tstr_column_to_float(dataset, i)\n",
        "# # convert class column to integers\n",
        "str_column_to_int(dataset, len(dataset[0])-1)\n",
        "# # normalize input variables\n",
        "minmax = dataset_minmax(dataset)\n",
        "normalize_dataset(dataset, minmax)\n",
        "# evaluate algorithm\n",
        "n_folds = 5\n",
        "l_rate = 0.9\n",
        "n_epoch = 5000\n",
        "n_hidden = 8\n",
        "scores = evaluate_algorithm(dataset, back_propagation, n_folds, l_rate, n_epoch, n_hidden)\n",
        "# print('Scores: %s' % scores)\n",
        "print('____TEST DATA____')\n",
        "print('Average Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}